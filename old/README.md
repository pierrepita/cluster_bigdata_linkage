# Cluster Big Data Linkage

Este repositÃ³rio configura um cluster de Big Data com Spark Standalone, HDFS e Elasticsearch, empacotado com Docker Compose e pronto para testes e experimentaÃ§Ãµes.

## ğŸ”§ Subindo o Cluster

```bash
docker compose up -d --build
```

VocÃª pode acessar:
- **Spark Master UI:** http://localhost:8080
- **Spark Job UI:** http://localhost:4040 (apÃ³s submissÃ£o de job)
- **Elasticsearch UI:** http://localhost:9200
- **Acesso SSH aos containers:** `ssh root@localhost -p <port>`, senha `bdlinkage`

---

## ğŸš€ Executando o exemplo PySpark (`spark_pi.py`)

```bash
docker exec -it spark-submit bash
spark-submit --master spark://spark-master:7077 /root/spark_pi.py
```

---

## ğŸ“¦ Trabalhando com o HDFS

### Subir arquivo para o HDFS

```bash
docker exec -it spark-master bash
hdfs dfs -put /opt/spark/README.md /user/root/
```

### Listar arquivos no HDFS

```bash
hdfs dfs -ls /user/root/
```

---

## ğŸ” Indexando e Buscando no Elasticsearch

### Indexando um JSON no Elasticsearch

```bash
curl -X POST http://localhost:9200/pessoas/_doc/1 \
  -H 'Content-Type: application/json' \
  -d '{
    "nome": "Ana Maria",
    "idade": 29,
    "cidade": "Recife"
  }'
```

### Busca `must` (todos os critÃ©rios precisam ser atendidos)

```bash
curl -X GET http://localhost:9200/pessoas/_search \
  -H 'Content-Type: application/json' \
  -d '{
    "query": {
      "bool": {
        "must": [
          { "match": { "nome": "Ana" }},
          { "match": { "cidade": "Recife" }}
        ]
      }
    }
  }'
```

### Busca `fuzzy` (similaridade de texto)

```bash
curl -X GET http://localhost:9200/pessoas/_search \
  -H 'Content-Type: application/json' \
  -d '{
    "query": {
      "fuzzy": {
        "nome": {
          "value": "Anna",
          "fuzziness": 1
        }
      }
    }
  }'
```

---

## ğŸ›‘ Encerrando o Cluster

```bash
docker compose down
```

---

## ğŸ“ Estrutura do Projeto

```text
cluster/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ spark/
â”‚   â””â”€â”€ spark-defaults.conf
â”œâ”€â”€ hadoop/
â”‚   â””â”€â”€ core-site.xml
â”‚   â””â”€â”€ hdfs-site.xml
â”œâ”€â”€ elasticsearch/
â”‚   â””â”€â”€ elasticsearch.yml
â”œâ”€â”€ ssh/
â”‚   â””â”€â”€ Dockerfile
â”‚   â””â”€â”€ authorized_keys
â”‚   â””â”€â”€ spark_pi.py
```