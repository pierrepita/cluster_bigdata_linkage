# spark-defaults.conf no nó barravento
# Definições do Master
spark.master                   		spark://barravento:7077
spark.driver.memory             	10g
spark.driver.cores              	4

# Definições dos executores em cada worker
spark.executor.cores            	4
spark.executor.memory           	12g
spark.executor.memoryOverhead		1536m

# Definições gerais
spark.serializer                	org.apache.spark.serializer.KryoSerializer
spark.eventLog.enabled          	true
spark.eventLog.dir              	file:///opt/spark/logs

# Informações de Cluster
spark.master                      	spark://barravento:7077
spark.hadoop.fs.defaultFS        	hdfs://barravento:9000


# Tuning geral
spark.sql.adaptive.enabled		true
## Ativa o Adaptive Query Execution (AQE), ajustando dinamicamente o plano físico durante a execução, baseado em estatísticas reais (tamanho de partições, skew, etc.). A ideia é melhor balanceamento de partições, menos OOM, joins escolhidos mais inteligentemente (por exemplo, converter um shuffle join em broadcast join em tempo de execução)

spark.sql.adaptive.skewJoin.enabled	true
## Específico do AQE: habilita tratamento de skew (desequilíbrio) em joins, corrige joins desbalanceados automaticamente.

spark.sql.files.maxPartitionBytes	64m
## Define o tamanho máximo de bytes que cada partição de leitura pode ter ao ler arquivos (CSV, Parquet, etc.).

spark.sql.broadcastTimeout		600
## Padrão é 5 minutos (300 s). Este é o Tempo máximo (em segundos) que o driver espera o broadcast de uma tabela pequena para os executores.

# ajuste para cada tamanho de conf
spark.sql.shuffle.partitions		48
## Número de partições geradas após operações de shuffle (ex.: groupBy, join, distinct). A ideia é fugir do padrão (200) para evitar "task overhead". O ideal é que este número seja: 2–3 * o número de cores totais. 

spark.sql.autoBroadcastJoinThreshold	100m
# O padrão é 10m. Define o limite de tamanho (em bytes) para que o Spark decida automaticamente fazer um broadcast join. Evita shuffle caro quando uma tabela de dimensão ainda cabe em memória.

spark.ui.showConsoleProgress     	true
# logs mais silenciosos
